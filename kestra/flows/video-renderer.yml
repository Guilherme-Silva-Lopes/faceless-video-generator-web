id: video-renderer
namespace: company.team
description: |
  Main video rendering workflow that:
  1. Generates B-Roll images with AI
  2. Creates voiceover with Kokoro TTS
  3. Generates captions with AssemblyAI
  4. Renders final video with FFmpeg

labels:
  project: faceless-video-generator
  type: subflow

inputs:
  - id: project_id
    type: STRING
    description: Project UUID
  - id: project_slug
    type: STRING
    description: URL-safe project name
  - id: script
    type: STRING
    description: Full video script
  - id: language
    type: STRING
    description: Target language code
    defaults: pt-BR
  - id: storage_folder
    type: STRING
    description: MinIO storage folder path

outputs:
  - id: final_video_url
    type: STRING
    value: "{{ read(outputs.upload_final_video.outputFiles['result.json']) | jq('.video_url') | first | default('') }}"

tasks:
  - id: get_voice_profile
    type: io.kestra.plugin.core.http.Request
    uri: "{{ kv('SUPABASE_URL') }}/rest/v1/voice_profiles?language=eq.{{ inputs.language }}&is_default=eq.true&limit=1"
    method: GET
    headers:
      apikey: "{{ kv('SUPABASE_ANON_KEY') }}"
      Authorization: "Bearer {{ kv('SUPABASE_ANON_KEY') }}"

  - id: parse_voice_profile
    type: io.kestra.plugin.scripts.python.Script
    inputFiles:
      profiles.json: "{{ outputs.get_voice_profile.body }}"
    script: |
      import json
      
      with open('profiles.json', 'r') as f:
          profiles = json.load(f)
      
      if profiles:
          profile = profiles[0]
          voice_id = profile['voice_id']
          speed = profile.get('speed', 1.0)
      else:
          voice_id = 'pt_BR-faber-medium'
          speed = 1.0
      
      result = {'voice_id': voice_id, 'speed': speed}
      
      with open('voice_config.json', 'w') as f:
          json.dump(result, f)
      
      print("Using voice: " + voice_id + " at speed " + str(speed))
    outputFiles:
      - voice_config.json

  - id: generate_all_images
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install google-generativeai requests > /dev/null 2>&1
    env:
      GOOGLE_API_KEY: "{{ kv('GOOGLE_API_KEY') }}"
      REPLICATE_API_TOKEN: "{{ kv('REPLICATE_API_TOKEN') }}"
    script: |
      import google.generativeai as genai
      import requests
      import os
      import json
      import re
      import time
      
      genai.configure(api_key=os.environ['GOOGLE_API_KEY'])
      model = genai.GenerativeModel('gemini-3-flash-preview')
      
      script = """{{ inputs.script }}"""[:10000]
      
      # Step 1: Generate prompts
      print("Generating image prompts...")
      prompt_lines = [
          "Analyze this script and create 6 image prompts for visual storytelling.",
          "",
          "Script:",
          script,
          "",
          "Create 6 scene prompts featuring the main female character in different story situations.",
          "All scenes should depict moments that do NOT reveal the ending.",
          "",
          "IMPORTANT CHARACTER GUIDELINES:",
          "- Describe a 50-70 year old woman with specific features",
          "- Avoid words like: wrinkles, weary, tired, weathered, aged, worn",
          "- Keep her appearance dignified and relatable",
          "",
          "Each prompt should:",
          "1. Start with detailed character description (same across all)",
          "2. Describe the scene, setting, action, emotion",
          "3. Be in ENGLISH (for image generation)",
          "4. Be 2-4 sentences maximum",
          "5. NOT contain any graphic content, violence, or people under 18",
          "",
          "OUTPUT FORMAT (JSON only):",
          '{"scene_prompts": [{"prompt_id": "scene_01", "prompt_text": "..."}, {"prompt_id": "scene_02", "prompt_text": "..."}, {"prompt_id": "scene_03", "prompt_text": "..."}, {"prompt_id": "scene_04", "prompt_text": "..."}, {"prompt_id": "scene_05", "prompt_text": "..."}, {"prompt_id": "scene_06", "prompt_text": "..."}]}'
      ]
      
      response = model.generate_content(
          "\n".join(prompt_lines),
          generation_config=genai.GenerationConfig(
              temperature=0.8,
              response_mime_type="application/json"
          )
      )
      
      try:
          prompts = json.loads(response.text)
      except:
          match = re.search(r'\{[\s\S]*\}', response.text)
          if match:
              prompts = json.loads(match.group())
          else:
              prompts = {"scene_prompts": []}
      
      scene_prompts = prompts.get('scene_prompts', [])
      print("Generated " + str(len(scene_prompts)) + " prompts")
      
      # Step 2: Generate images via Replicate (raw HTTP like n8n)
      replicate_token = os.environ['REPLICATE_API_TOKEN']
      print("Token configured: " + replicate_token[:10] + "...")
      
      headers = {
          'Authorization': 'Bearer ' + replicate_token,
          'Content-Type': 'application/json',
          'Prefer': 'wait'
      }
      
      for i, prompt_data in enumerate(scene_prompts[:6]):
          prompt_id = prompt_data.get('prompt_id', 'scene_' + str(i+1).zfill(2))
          prompt_text = prompt_data.get('prompt_text', '')
          
          print("Generating image " + str(i+1) + "/6: " + prompt_id)
          
          payload = {
              "input": {
                  "width": 1024,
                  "height": 768,
                  "prompt": prompt_text,
                  "go_fast": True,
                  "output_format": "jpg",
                  "guidance_scale": 0,
                  "output_quality": 80,
                  "num_inference_steps": 8
              }
          }
          
          # Retry with exponential backoff
          max_retries = 3
          for retry in range(max_retries):
              try:
                  response = requests.post(
                      'https://api.replicate.com/v1/models/prunaai/z-image-turbo/predictions',
                      headers=headers,
                      json=payload,
                      timeout=60
                  )
                  
                  print("  Response status: " + str(response.status_code))
                  
                  if response.status_code in [200, 201]:
                      result = response.json()
                      prediction_id = result.get('id')
                      print("  Prediction ID: " + str(prediction_id) + ", status: " + result.get('status', 'unknown'))
                      
                      # If status is not succeeded, poll for completion
                      if result.get('status') not in ['succeeded', 'failed', 'canceled']:
                          print("  Polling for completion...")
                          poll_url = "https://api.replicate.com/v1/predictions/" + prediction_id
                          poll_headers = {'Authorization': 'Bearer ' + replicate_token}
                          
                          for poll_attempt in range(30):  # Max 60 seconds
                              time.sleep(2)
                              poll_response = requests.get(poll_url, headers=poll_headers, timeout=10)
                              if poll_response.status_code == 200:
                                  result = poll_response.json()
                                  status = result.get('status', 'unknown')
                                  if status == 'succeeded':
                                      print("  Poll: succeeded")
                                      break
                                  elif status in ['failed', 'canceled']:
                                      print("  Poll: " + status)
                                      break
                                  else:
                                      if poll_attempt % 5 == 0:
                                          print("  Poll " + str(poll_attempt+1) + ": " + status)
                      
                      # Now check if succeeded
                      if result.get('status') == 'succeeded' and result.get('output'):
                          output_url = result['output']
                          if isinstance(output_url, list):
                              output_url = output_url[0]
                          
                          print("  Downloading from: " + output_url[:60] + "...")
                          img_response = requests.get(output_url, timeout=30)
                          
                          if img_response.status_code == 200:
                              with open(prompt_id + '.jpg', 'wb') as f:
                                  f.write(img_response.content)
                              print("  Saved: " + prompt_id + ".jpg (" + str(len(img_response.content)) + " bytes)")
                              break  # Success
                          else:
                              print("  Failed to download: " + str(img_response.status_code))
                      else:
                          print("  Failed: status=" + result.get('status', 'unknown') + ", error=" + str(result.get('error', ''))[:100])
                  elif response.status_code == 429:
                      wait_time = (retry + 1) * 15
                      print("  Rate limited, waiting " + str(wait_time) + "s (retry " + str(retry+1) + "/" + str(max_retries) + ")")
                      time.sleep(wait_time)
                  else:
                      print("  API error: " + str(response.status_code) + " - " + response.text[:200])
                      break
                      
              except Exception as e:
                  print("  Exception: " + str(e)[:150])
                  if retry < max_retries - 1:
                      time.sleep(10)
          
          # Delay between requests
          if i < 5:
              time.sleep(3)
      
      print("Image generation complete")
    outputFiles:
      - "*.jpg"

  - id: create_all_clips
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - apt-get update -qq && apt-get install -y -qq ffmpeg > /dev/null 2>&1
    inputFiles:
      scene_01.jpg: "{{ outputs.generate_all_images.outputFiles['scene_01.jpg'] | default('') }}"
      scene_02.jpg: "{{ outputs.generate_all_images.outputFiles['scene_02.jpg'] | default('') }}"
      scene_03.jpg: "{{ outputs.generate_all_images.outputFiles['scene_03.jpg'] | default('') }}"
      scene_04.jpg: "{{ outputs.generate_all_images.outputFiles['scene_04.jpg'] | default('') }}"
      scene_05.jpg: "{{ outputs.generate_all_images.outputFiles['scene_05.jpg'] | default('') }}"
      scene_06.jpg: "{{ outputs.generate_all_images.outputFiles['scene_06.jpg'] | default('') }}"
    script: |
      import subprocess
      import os
      
      clips = []
      
      for i in range(1, 7):
          scene_id = "scene_" + str(i).zfill(2)
          input_file = scene_id + ".jpg"
          output_file = scene_id + ".mp4"
          
          if os.path.exists(input_file) and os.path.getsize(input_file) > 1000:
              cmd = [
                  'ffmpeg', '-y',
                  '-loop', '1',
                  '-i', input_file,
                  '-vf', "scale=5760:3240,zoompan=z='1+on*0.0005':d=300:x='trunc(iw/2-(iw/zoom/2))':y='trunc(ih/2-(ih/zoom/2))':s=1920x1080:fps=30,format=yuv420p",
                  '-c:v', 'libx264',
                  '-t', '10',
                  '-r', '30',
                  '-crf', '23',
                  '-preset', 'fast',
                  output_file
              ]
          else:
              print("No image for " + scene_id + ", creating placeholder")
              cmd = [
                  'ffmpeg', '-y',
                  '-f', 'lavfi',
                  '-i', 'color=c=black:s=1920x1080:d=10:r=30',
                  '-c:v', 'libx264',
                  '-preset', 'fast',
                  output_file
              ]
          
          result = subprocess.run(cmd, capture_output=True, text=True)
          
          if result.returncode == 0:
              clips.append(output_file)
              print("Created: " + output_file)
          else:
              print("Error creating " + output_file + ": " + result.stderr[:200])
      
      # Merge all clips
      if clips:
          with open('concat.txt', 'w') as f:
              for clip in clips:
                  f.write("file '" + clip + "'\n")
          
          cmd = [
              'ffmpeg', '-y',
              '-f', 'concat',
              '-safe', '0',
              '-i', 'concat.txt',
              '-c:v', 'libx264',
              '-preset', 'fast',
              '-crf', '23',
              'loop_video.mp4'
          ]
          
          result = subprocess.run(cmd, capture_output=True, text=True)
          
          if result.returncode == 0:
              print("Created loop_video.mp4")
          else:
              raise Exception("Failed to merge clips: " + result.stderr)
      else:
          raise Exception("No clips created")
    outputFiles:
      - loop_video.mp4

  - id: generate_voiceover
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - apt-get update -qq && apt-get install -y -qq ffmpeg > /dev/null 2>&1
      - pip install requests > /dev/null 2>&1
    env:
      KOKORO_BASE_URL: "{{ kv('KOKO_BASE_URL') }}"
      KOKORO_API_KEY: "{{ kv('KOKORO_API') }}"
    inputFiles:
      voice_config.json: "{{ outputs.parse_voice_profile.outputFiles['voice_config.json'] }}"
    script: |
      import requests
      import os
      import json
      import subprocess
      import re
      
      base_url = os.environ['KOKORO_BASE_URL'].rstrip('/')
      api_key = os.environ['KOKORO_API_KEY']
      
      with open('voice_config.json', 'r') as f:
          voice_config = json.load(f)
      
      language = "{{ inputs.language }}"
      speed = voice_config.get('speed', 1.0)
      
      # Map language to Kokoro voice and lang code
      voice_map = {
          'pt-BR': {'voice': 'pf_dora', 'lang': 'p'},
          'en-US': {'voice': 'af_heart', 'lang': 'a'},
          'es-ES': {'voice': 'ef_dora', 'lang': 'e'},
          'ja-JP': {'voice': 'jf_alpha', 'lang': 'j'},
          'it-IT': {'voice': 'if_sara', 'lang': 'i'}
      }
      
      voice_config_lang = voice_map.get(language, voice_map['en-US'])
      voice_id = voice_config_lang['voice']
      lang_code = voice_config_lang['lang']
      
      script = """{{ inputs.script }}"""
      script = script.replace('\n\n', '. ').replace('\n', ' ')
      script = ' '.join(script.split())
      
      headers = {'Content-Type': 'application/json'}
      if api_key and api_key.strip() and api_key != 'null':
          headers['Authorization'] = api_key
      
      print("Generating voiceover with voice: " + voice_id + " (lang: " + lang_code + ")")
      print("Total script length: " + str(len(script)) + " characters")
      
      # Split script into chunks of ~2000 chars at sentence boundaries
      def split_into_chunks(text, max_chars=2000):
          sentences = re.split(r'(?<=[.!?])\s+', text)
          chunks = []
          current_chunk = ""
          
          for sentence in sentences:
              if len(current_chunk) + len(sentence) < max_chars:
                  current_chunk += sentence + " "
              else:
                  if current_chunk.strip():
                      chunks.append(current_chunk.strip())
                  current_chunk = sentence + " "
          
          if current_chunk.strip():
              chunks.append(current_chunk.strip())
          
          return chunks
      
      chunks = split_into_chunks(script)
      print("Split into " + str(len(chunks)) + " chunks")
      
      audio_files = []
      
      for idx, chunk in enumerate(chunks):
          print("Processing chunk " + str(idx + 1) + "/" + str(len(chunks)) + " (" + str(len(chunk)) + " chars)")
          
          payload = {
              'model': 'model_q4',
              'input': chunk,
              'voice': voice_id,
              'speed': speed,
              'response_format': 'mp3',
              'lang': lang_code
          }
          
          # Retry with exponential backoff for TTS
          max_retries = 3
          for retry in range(max_retries):
              try:
                  timeout_val = 120 + (retry * 60)  # 120s, 180s, 240s
                  response = requests.post(
                      base_url + "/api/v1/audio/speech",
                      headers=headers,
                      json=payload,
                      timeout=timeout_val
                  )
                  
                  if response.status_code == 200:
                      filename = "part_" + str(idx).zfill(3) + ".mp3"
                      with open(filename, 'wb') as f:
                          f.write(response.content)
                      audio_files.append(filename)
                      print("  Generated: " + filename)
                      break  # Success
                  else:
                      print("  Error: " + str(response.status_code) + " - " + response.text[:100])
                      if retry < max_retries - 1:
                          wait_time = (retry + 1) * 15
                          print("  Retrying in " + str(wait_time) + "s...")
                          time.sleep(wait_time)
              except Exception as e:
                  print("  Exception (attempt " + str(retry+1) + "): " + str(e)[:80])
                  if retry < max_retries - 1:
                      wait_time = (retry + 1) * 20  # 20s, 40s
                      print("  Retrying in " + str(wait_time) + "s...")
                      time.sleep(wait_time)
      
      if not audio_files:
          raise Exception("No audio files generated")
      
      # Merge audio files with ffmpeg
      with open('files.txt', 'w') as f:
          for audio in audio_files:
              f.write("file '" + audio + "'\n")
      
      cmd = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", "files.txt", "-c", "copy", "voiceover.mp3"]
      result = subprocess.run(cmd, capture_output=True, text=True)
      
      if result.returncode != 0:
          print("FFmpeg error: " + result.stderr)
          raise Exception("Failed to merge audio")
      
      print("Generated voiceover.mp3")
    outputFiles:
      - voiceover.mp3

  - id: transcribe_audio
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install requests > /dev/null 2>&1
    env:
      ASSEMBLYAI_API_KEY: "{{ kv('ASSEMBLYAI_API_KEY') }}"
    inputFiles:
      voiceover.mp3: "{{ outputs.generate_voiceover.outputFiles['voiceover.mp3'] }}"
    script: |
      import requests
      import os
      import time
      
      api_key = os.environ['ASSEMBLYAI_API_KEY']
      headers = {'authorization': api_key}
      
      language_code = "{{ inputs.language }}"
      
      lang_map = {
          'pt-BR': 'pt',
          'en-US': 'en',
          'es-ES': 'es',
          'ja-JP': 'ja',
          'it-IT': 'it'
      }
      aai_lang = lang_map.get(language_code, 'en')
      
      print("Uploading audio to AssemblyAI...")
      with open('voiceover.mp3', 'rb') as f:
          upload_response = requests.post(
              'https://api.assemblyai.com/v2/upload',
              headers=headers,
              data=f
          )
      
      audio_url = upload_response.json()['upload_url']
      print("Upload complete")
      
      transcript_request = {
          'audio_url': audio_url,
          'language_code': aai_lang,
          'punctuate': True,
          'format_text': True
      }
      
      response = requests.post(
          'https://api.assemblyai.com/v2/transcript',
          headers=headers,
          json=transcript_request
      )
      
      transcript_id = response.json()['id']
      print("Transcription started: " + transcript_id)
      
      while True:
          response = requests.get(
              'https://api.assemblyai.com/v2/transcript/' + transcript_id,
              headers=headers
          )
          result = response.json()
          
          if result['status'] == 'completed':
              break
          elif result['status'] == 'error':
              raise Exception("Transcription failed: " + str(result.get('error')))
          
          print("Status: " + result['status'])
          time.sleep(5)
      
      srt_response = requests.get(
          "https://api.assemblyai.com/v2/transcript/" + transcript_id + "/srt",
          headers=headers,
          params={'chars_per_caption': 42}
      )
      
      srt_content = srt_response.text
      
      # Adjust timing
      lines = srt_content.split('\n')
      adjusted_lines = []
      
      def parse_time(t):
          h, m, rest = t.split(':')
          s, ms = rest.split(',')
          return int(h)*3600000 + int(m)*60000 + int(s)*1000 + int(ms)
      
      def format_time(ms):
          if ms < 0:
              ms = 0
          h = ms // 3600000
          ms = ms % 3600000
          m = ms // 60000
          ms = ms % 60000
          s = ms // 1000
          ms = ms % 1000
          return str(h).zfill(2) + ":" + str(m).zfill(2) + ":" + str(s).zfill(2) + "," + str(ms).zfill(3)
      
      SHIFT_MS = -600
      
      for line in lines:
          if ' --> ' in line:
              start, end = line.split(' --> ')
              start_ms = parse_time(start.strip()) + SHIFT_MS
              end_ms = parse_time(end.strip()) + SHIFT_MS
              line = format_time(start_ms) + " --> " + format_time(end_ms)
          adjusted_lines.append(line)
      
      adjusted_srt = '\n'.join(adjusted_lines)
      
      with open('captions.srt', 'w', encoding='utf-8') as f:
          f.write(adjusted_srt)
      
      print("Captions generated and adjusted")
    outputFiles:
      - captions.srt

  - id: render_final_video
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - apt-get update -qq && apt-get install -y -qq ffmpeg fonts-dejavu > /dev/null 2>&1
    inputFiles:
      loop_video.mp4: "{{ outputs.create_all_clips.outputFiles['loop_video.mp4'] }}"
      voiceover.mp3: "{{ outputs.generate_voiceover.outputFiles['voiceover.mp3'] }}"
      captions.srt: "{{ outputs.transcribe_audio.outputFiles['captions.srt'] }}"
    script: |
      import subprocess
      import os
      
      project_slug = "{{ inputs.project_slug }}"
      output_file = project_slug + ".mp4"
      
      probe_cmd = [
          'ffprobe', '-v', 'error',
          '-show_entries', 'format=duration',
          '-of', 'default=noprint_wrappers=1:nokey=1',
          'voiceover.mp3'
      ]
      result = subprocess.run(probe_cmd, capture_output=True, text=True)
      audio_duration = float(result.stdout.strip())
      print("Audio duration: " + str(audio_duration) + "s")
      
      srt_path = os.path.abspath('captions.srt').replace('\\', '/').replace(':', '\\:')
      
      cmd = [
          'ffmpeg', '-y',
          '-stream_loop', '-1',
          '-i', 'loop_video.mp4',
          '-i', 'voiceover.mp3',
          '-vf', "subtitles='" + srt_path + "':force_style='FontSize=24,PrimaryColour=&H00FFFF&,OutlineColour=&H000000&,Outline=2,Alignment=2,MarginV=50'",
          '-map', '0:v',
          '-map', '1:a',
          '-c:v', 'libx264',
          '-preset', 'medium',
          '-crf', '23',
          '-c:a', 'aac',
          '-b:a', '192k',
          '-t', str(audio_duration),
          '-shortest',
          output_file
      ]
      
      print("Rendering final video...")
      result = subprocess.run(cmd, capture_output=True, text=True)
      
      if result.returncode != 0:
          print("FFmpeg error with subtitles, trying without...")
          cmd_no_subs = [
              'ffmpeg', '-y',
              '-stream_loop', '-1',
              '-i', 'loop_video.mp4',
              '-i', 'voiceover.mp3',
              '-map', '0:v',
              '-map', '1:a',
              '-c:v', 'libx264',
              '-preset', 'medium',
              '-crf', '23',
              '-c:a', 'aac',
              '-b:a', '192k',
              '-t', str(audio_duration),
              '-shortest',
              output_file
          ]
          result = subprocess.run(cmd_no_subs, capture_output=True, text=True)
          
          if result.returncode != 0:
              raise Exception("Failed to render video: " + result.stderr)
          print("Rendered without subtitles (fallback)")
      else:
          print("Rendered with subtitles")
      
      file_size = os.path.getsize(output_file) / (1024*1024)
      print("Final video: " + output_file + " (" + str(round(file_size, 1)) + " MB)")
    outputFiles:
      - "*.mp4"

  - id: upload_final_video
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install minio > /dev/null 2>&1
    env:
      MINIO_ENDPOINT: "{{ kv('MINIO_ENDPOINT') }}"
      MINIO_ACCESS_KEY: "{{ kv('MINIO_ACCESS_KEY') }}"
      MINIO_SECRET_KEY: "{{ kv('MINIO_SECRET_KEY') }}"
      MINIO_BUCKET: "{{ kv('MINIO_BUCKET') }}"
    inputFiles:
      final_video.mp4: "{{ outputs.render_final_video.outputFiles[inputs.project_slug + '.mp4'] }}"
    script: |
      from minio import Minio
      from urllib.parse import urlparse
      import os
      import json
      
      endpoint = os.environ['MINIO_ENDPOINT']
      access_key = os.environ['MINIO_ACCESS_KEY']
      secret_key = os.environ['MINIO_SECRET_KEY']
      bucket = os.environ['MINIO_BUCKET']
      
      storage_folder = "{{ inputs.storage_folder }}"
      project_slug = "{{ inputs.project_slug }}"
      
      parsed = urlparse(endpoint)
      host = parsed.netloc or parsed.path
      secure = parsed.scheme == 'https'
      
      if ':' in host:
          host_parts = host.split(':')
          host = host_parts[0]
          if parsed.port:
              host = host + ":" + str(parsed.port)
      
      client = Minio(
          host,
          access_key=access_key,
          secret_key=secret_key,
          secure=secure
      )
      
      object_name = storage_folder + "/" + project_slug + ".mp4"
      
      client.fput_object(
          bucket,
          object_name,
          'final_video.mp4',
          content_type='video/mp4'
      )
      
      video_url = endpoint.rstrip('/') + "/" + bucket + "/" + object_name
      
      print("Uploaded to: " + video_url)
      
      with open('result.json', 'w') as f:
          json.dump({'video_url': video_url}, f)
    outputFiles:
      - result.json
